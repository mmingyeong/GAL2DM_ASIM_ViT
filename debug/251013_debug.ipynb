{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… sys.path ì¶”ê°€ ì™„ë£Œ: /home/mingyeong/2510_GAL2DM_ASIM_ViT\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# í˜„ì¬ ë…¸íŠ¸ë¶ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ê²½ë¡œ(src ìˆëŠ” ê³³) ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# í™•ì¸\n",
    "print(\"âœ… sys.path ì¶”ê°€ ì™„ë£Œ:\", project_root)\n",
    "\n",
    "from src.data_loader import get_dataloader, sanity_check_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 00:19:59,227 | INFO | data_loader | ğŸ“‚ Split 'train': 8202 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 00:19:59,251 | INFO | data_loader | [SanityCheck] train[0] = 0.hdf5 | x.shape=(2, 128, 128, 128), y.shape=(1, 1, 128, 128, 128) | x stats: min=-1329, max=1756, mean=0.2343 | y stats: min=0.02697, max=164.8, mean=1\n",
      "2025-10-14 00:19:59,315 | INFO | data_loader | ğŸ“‚ Split 'train': 8202 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 00:19:59,317 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 8202 | target: rho\n",
      "2025-10-14 00:19:59,317 | INFO | data_loader | ğŸ“¦ Split='train' | batches of 1 | files=8202 | target='rho' | dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ”§ Sanity check (first training file) ===\n",
      "\n",
      "=== ğŸš€ Initializing DataLoaders ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 00:19:59,443 | INFO | data_loader | ğŸ“‚ Split 'val': 2051 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 00:19:59,444 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 2051 | target: rho\n",
      "2025-10-14 00:19:59,445 | INFO | data_loader | ğŸ“¦ Split='val' | batches of 1 | files=2051 | target='rho' | dtype=torch.float32\n",
      "2025-10-14 00:19:59,511 | INFO | data_loader | ğŸ“‚ Split 'test': 1267 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 00:19:59,512 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 1267 | target: rho\n",
      "2025-10-14 00:19:59,513 | INFO | data_loader | ğŸ“¦ Split='test' | batches of 1 | files=1267 | target='rho' | dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ” Inspecting train loader ===\n",
      "Input  shape: (1, 2, 128, 128, 128)\n",
      "Target shape: (1, 1, 1, 1, 128, 128, 128)\n",
      "Input stats:  min=-1.33e+03, max=1.76e+03, mean=0.234\n",
      "Target stats: min=0.027, max=165, mean=1\n",
      "\n",
      "=== ğŸ” Inspecting val loader ===\n",
      "Input  shape: (1, 2, 128, 128, 128)\n",
      "Target shape: (1, 1, 1, 1, 128, 128, 128)\n",
      "Input stats:  min=-1.27e+03, max=1.67e+03, mean=0.158\n",
      "Target stats: min=0.042, max=217, mean=1\n",
      "\n",
      "=== ğŸ” Inspecting test loader ===\n",
      "Input  shape: (1, 2, 128, 128, 128)\n",
      "Target shape: (1, 1, 1, 1, 128, 128, 128)\n",
      "Input stats:  min=-1.36e+03, max=1.78e+03, mean=-0.219\n",
      "Target stats: min=0.0394, max=378, mean=1\n",
      "\n",
      "âœ… All loaders initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# ğŸ” data_loader.py ê°„ë‹¨ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸ (Jupyter)\n",
    "# ======================================================\n",
    "import os\n",
    "#import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1ï¸âƒ£ ëª¨ë“ˆ import\n",
    "from src.data_loader import get_dataloader, sanity_check_sample\n",
    "\n",
    "# 2ï¸âƒ£ YAML íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "yaml_path = \"/home/mingyeong/2510_GAL2DM_ASIM_ViT/etc/asim_paths.yaml\"   # ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "# 3ï¸âƒ£ Sanity check: í•˜ë‚˜ì˜ íŒŒì¼ì—ì„œ key í™•ì¸\n",
    "print(\"=== ğŸ”§ Sanity check (first training file) ===\")\n",
    "sanity_check_sample(yaml_path, split=\"train\", idx=0, target_field=\"rho\")\n",
    "\n",
    "# 4ï¸âƒ£ ë°ì´í„°ë¡œë” ìƒì„±\n",
    "print(\"\\n=== ğŸš€ Initializing DataLoaders ===\")\n",
    "train_loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"train\",\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    target_field=\"rho\"\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"val\",\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    target_field=\"rho\"\n",
    ")\n",
    "\n",
    "test_loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"test\",\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    target_field=\"rho\"\n",
    ")\n",
    "\n",
    "# 5ï¸âƒ£ ë°°ì¹˜ í•œ ê°œ í™•ì¸\n",
    "def inspect_batch(loader, name=\"train\"):\n",
    "    print(f\"\\n=== ğŸ” Inspecting {name} loader ===\")\n",
    "    for x, y in loader:\n",
    "        print(f\"Input  shape: {tuple(x.shape)}\")   # (B, 2, 128, 128, 128)\n",
    "        print(f\"Target shape: {tuple(y.shape)}\")   # (B, 1, 128, 128, 128)\n",
    "        print(f\"Input stats:  min={x.min():.3g}, max={x.max():.3g}, mean={x.mean():.3g}\")\n",
    "        print(f\"Target stats: min={y.min():.3g}, max={y.max():.3g}, mean={y.mean():.3g}\")\n",
    "        break  # í•œ ë°°ì¹˜ë§Œ í™•ì¸\n",
    "\n",
    "inspect_batch(train_loader, \"train\")\n",
    "inspect_batch(val_loader, \"val\")\n",
    "inspect_batch(test_loader, \"test\")\n",
    "\n",
    "print(\"\\nâœ… All loaders initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch version: 2.4.1\n",
      "ğŸš€ GPU available: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: í™˜ê²½ í™•ì¸\n",
    "import torch\n",
    "\n",
    "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸš€ GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"ğŸ§  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"ğŸ’¾ Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“¦ Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“ˆ Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"ğŸŸ¢ Free memory in reserved: {free_memory:.2f} GiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 00:19:59,890 | INFO | data_loader | ğŸ“‚ Split 'train': 8202 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 00:19:59,891 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 8202 | target: rho\n",
      "2025-10-14 00:19:59,891 | INFO | data_loader | ğŸ“¦ Split='train' | batches of 2 | files=8202 | target='rho' | dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample loaded: input shape = (2, 2, 128, 128, 128), output shape = (2, 1, 1, 1, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ë°ì´í„°ì…‹ ë¡œë”© (A-SIM ê·œê²©)\n",
    "import os, sys\n",
    "import torch\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸(srcê°€ ìˆëŠ” ìƒìœ„ í´ë”) ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# A-SIMìš© ë°ì´í„°ë¡œë” ì„í¬íŠ¸\n",
    "from src.data_loader import get_dataloader\n",
    "\n",
    "# asim_paths.yaml ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆë‹¤ê³  ê°€ì •)\n",
    "yaml_path = os.path.join(project_root, \"etc/asim_paths.yaml\")\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "# - split='train'ì€ training/*.hdf5 ì¤‘ ì•ë¶€ë¶„(ê¸°ë³¸ 80%)ì„ ì‚¬ìš©\n",
    "# - target_field='rho' ì´ë©´ output_rhoë¥¼ íƒ€ê¹ƒìœ¼ë¡œ ì‚¬ìš©\n",
    "loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"train\",             # 'val' / 'test'ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    target_field=\"rho\",        # 'tscphi' ì‚¬ìš© ì‹œ í¬í…ì…œ ìŠ¤ì¼€ì¼/í‰ê·  ì œê±° ìë™ ì ìš©\n",
    "    train_val_split=0.8,       # train/val ë¹„ìœ¨ ì¡°ì • ê°€ëŠ¥\n",
    ")\n",
    "\n",
    "# í•œ ë°°ì¹˜ í™•ì¸\n",
    "x, y = next(iter(loader))\n",
    "print(f\"âœ… Sample loaded: input shape = {tuple(x.shape)}, output shape = {tuple(y.shape)}\")\n",
    "# ê¸°ëŒ€ í˜•ìƒ: input=(B, 2, 128, 128, 128), output=(B, 1, 128, 128, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ViT model (full) loaded and set to training mode.\n",
      "ğŸ“ Dummy input: torch.Size([2, 2, 128, 128, 128]) â†’ Prediction shape: torch.Size([2, 1, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: ViT ì´ˆê¸°í™” for scalar regression from full 3D volume (A-SIM, 128Â³ cube)\n",
    "from src.model import ViT3D\n",
    "import torch\n",
    "\n",
    "# ì…ë ¥ í¬ê¸° (A-SIM subcube)\n",
    "input_shape = (128, 128, 128)  # (D, H, W)\n",
    "patch_spatial = 16              # 128 / 16 = 8 patches\n",
    "patch_depth = 16                # 128 / 16 = 8 patches\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_name = \"full\"\n",
    "\n",
    "model = ViT3D(\n",
    "    image_size=input_shape[1],\n",
    "    frames=input_shape[0],\n",
    "    image_patch_size=patch_spatial,\n",
    "    frame_patch_size=patch_depth,\n",
    "    dim=256,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    mlp_dim=512,\n",
    "    in_channels=2,   # ğŸ”¸ A-SIM ì…ë ¥ ì±„ë„ ìˆ˜: ngal, vpec\n",
    "    out_channels=1   # ğŸ”¸ ì¶œë ¥: ë‹¨ì¼ ë°€ë„ì¥(ë˜ëŠ” í¬í…ì…œ)\n",
    ").to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Dummy inputìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "x_dummy = torch.randn(2, 2, *input_shape).to(device)  # [B, C, D, H, W]\n",
    "y_dummy = model(x_dummy)\n",
    "\n",
    "print(f\"âœ… ViT model ({model_name}) loaded and set to training mode.\")\n",
    "print(f\"ğŸ“ Dummy input: {x_dummy.shape} â†’ Prediction shape: {y_dummy.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "======================================================================================================================================================\n",
       "ViT3D                                              [2, 2, 128, 128, 128]     [2, 1, 128, 128, 128]     131,072                   --\n",
       "â”œâ”€Sequential: 1-1                                  [2, 2, 128, 128, 128]     [2, 512, 256]             --                        --\n",
       "â”‚    â””â”€Rearrange: 2-1                              [2, 2, 128, 128, 128]     [2, 512, 8192]            --                        --\n",
       "â”‚    â””â”€LayerNorm: 2-2                              [2, 512, 8192]            [2, 512, 8192]            16,384                    --\n",
       "â”‚    â””â”€Linear: 2-3                                 [2, 512, 8192]            [2, 512, 256]             2,097,408                 --\n",
       "â”‚    â””â”€LayerNorm: 2-4                              [2, 512, 256]             [2, 512, 256]             512                       --\n",
       "â”œâ”€Dropout: 1-2                                     [2, 512, 256]             [2, 512, 256]             --                        --\n",
       "â”œâ”€Transformer: 1-3                                 [2, 512, 256]             [2, 512, 256]             --                        --\n",
       "â”‚    â””â”€ModuleList: 2-5                             --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-1                        --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-2                        --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-3                        --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                        --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-5                        --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-6                        --                        --                        788,480                   --\n",
       "â”œâ”€Sequential: 1-4                                  [2, 512, 256]             [2, 512, 4096]            --                        --\n",
       "â”‚    â””â”€LayerNorm: 2-6                              [2, 512, 256]             [2, 512, 256]             512                       --\n",
       "â”‚    â””â”€Linear: 2-7                                 [2, 512, 256]             [2, 512, 4096]            1,052,672                 --\n",
       "======================================================================================================================================================\n",
       "Total params: 8,029,440\n",
       "Trainable params: 8,029,440\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 15.80\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 33.55\n",
       "Forward/backward pass size (MB): 257.95\n",
       "Params size (MB): 31.59\n",
       "Estimated Total Size (MB): 323.10\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Batch=2, Channels=2, D=H=W=128\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(2, 2, 128, 128, 128),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"],\n",
    "    depth=3,            # keep output readable\n",
    "    device=str(device), # run summary on the same device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
