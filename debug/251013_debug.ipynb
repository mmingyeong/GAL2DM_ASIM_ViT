{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… sys.path ì¶”ê°€ ì™„ë£Œ: /home/mingyeong/2510_GAL2DM_ASIM_ViT\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# í˜„ì¬ ë…¸íŠ¸ë¶ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ê²½ë¡œ(src ìˆëŠ” ê³³) ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# í™•ì¸\n",
    "print(\"âœ… sys.path ì¶”ê°€ ì™„ë£Œ:\", project_root)\n",
    "\n",
    "from src.data_loader import get_dataloader, sanity_check_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 20:32:40,931 | INFO | data_loader | ğŸ“‚ Split 'train': 8202 files (8202/10253 train-val split, 1267 test files)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ”§ Sanity check (first training file) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 20:33:20,282 | INFO | data_loader | âœ… Valid files kept: 8202 / 8202\n",
      "2025-10-14 20:33:20,342 | INFO | data_loader | [SanityCheck] train[0] = 0.hdf5 | x.shape=(2, 128, 128, 128), y.shape=(128, 128, 128) | x stats: min=-1329, max=1756, mean=0.2343 | y stats: min=0.02697, max=164.8, mean=1\n",
      "2025-10-14 20:33:20,418 | INFO | data_loader | ğŸ“‚ Split 'train': 8202 files (8202/10253 train-val split, 1267 test files)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸš€ Initializing DataLoaders ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 20:33:25,820 | INFO | data_loader | âœ… Valid files kept: 8202 / 8202\n",
      "2025-10-14 20:33:25,824 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 8202 | target: rho\n",
      "2025-10-14 20:33:25,825 | INFO | data_loader | ğŸ“¦ Split='train' | batches of 1 | files=8202 | target='rho' | dtype=torch.float32\n",
      "2025-10-14 20:33:26,046 | INFO | data_loader | ğŸ“‚ Split 'val': 2051 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 20:33:53,578 | WARNING | data_loader | âš ï¸ Filtered out 5 invalid file(s) without required keys.\n",
      "2025-10-14 20:33:53,581 | INFO | data_loader | âœ… Valid files kept: 2046 / 2051\n",
      "2025-10-14 20:33:53,582 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 2046 | target: rho\n",
      "2025-10-14 20:33:53,583 | INFO | data_loader | ğŸ“¦ Split='val' | batches of 1 | files=2046 | target='rho' | dtype=torch.float32\n",
      "2025-10-14 20:33:53,653 | INFO | data_loader | ğŸ“‚ Split 'test': 1267 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 20:34:08,468 | WARNING | data_loader | âš ï¸ Filtered out 3 invalid file(s) without required keys.\n",
      "2025-10-14 20:34:08,470 | INFO | data_loader | âœ… Valid files kept: 1264 / 1267\n",
      "2025-10-14 20:34:08,471 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 1264 | target: rho\n",
      "2025-10-14 20:34:08,472 | INFO | data_loader | ğŸ“¦ Split='test' | batches of 1 | files=1264 | target='rho' | dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ” Inspecting train loader ===\n",
      "Input  shape: (1, 2, 128, 128, 128)\n",
      "Target shape: (1, 1, 128, 128, 128)\n",
      "Input stats:  min=-1.33e+03, max=1.76e+03, mean=0.234\n",
      "Target stats: min=0.027, max=165, mean=1\n",
      "\n",
      "=== ğŸ” Inspecting val loader ===\n",
      "Input  shape: (1, 2, 128, 128, 128)\n",
      "Target shape: (1, 1, 128, 128, 128)\n",
      "Input stats:  min=-1.27e+03, max=1.67e+03, mean=0.158\n",
      "Target stats: min=0.042, max=217, mean=1\n",
      "\n",
      "=== ğŸ” Inspecting test loader ===\n",
      "Input  shape: (1, 2, 128, 128, 128)\n",
      "Target shape: (1, 1, 128, 128, 128)\n",
      "Input stats:  min=-1.36e+03, max=1.78e+03, mean=-0.219\n",
      "Target stats: min=0.0394, max=378, mean=1\n",
      "\n",
      "âœ… All loaders initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# ğŸ” data_loader.py ê°„ë‹¨ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸ (Jupyter)\n",
    "# ======================================================\n",
    "import os\n",
    "#import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1ï¸âƒ£ ëª¨ë“ˆ import\n",
    "from src.data_loader import get_dataloader, sanity_check_sample\n",
    "\n",
    "# 2ï¸âƒ£ YAML íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "yaml_path = \"/home/mingyeong/2510_GAL2DM_ASIM_ViT/etc/asim_paths.yaml\"   # ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "# 3ï¸âƒ£ Sanity check: í•˜ë‚˜ì˜ íŒŒì¼ì—ì„œ key í™•ì¸\n",
    "print(\"=== ğŸ”§ Sanity check (first training file) ===\")\n",
    "sanity_check_sample(yaml_path, split=\"train\", idx=0, target_field=\"rho\")\n",
    "\n",
    "# 4ï¸âƒ£ ë°ì´í„°ë¡œë” ìƒì„±\n",
    "print(\"\\n=== ğŸš€ Initializing DataLoaders ===\")\n",
    "train_loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"train\",\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    target_field=\"rho\"\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"val\",\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    target_field=\"rho\"\n",
    ")\n",
    "\n",
    "test_loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"test\",\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    target_field=\"rho\"\n",
    ")\n",
    "\n",
    "# 5ï¸âƒ£ ë°°ì¹˜ í•œ ê°œ í™•ì¸\n",
    "def inspect_batch(loader, name=\"train\"):\n",
    "    print(f\"\\n=== ğŸ” Inspecting {name} loader ===\")\n",
    "    for x, y in loader:\n",
    "        print(f\"Input  shape: {tuple(x.shape)}\")   # (B, 2, 128, 128, 128)\n",
    "        print(f\"Target shape: {tuple(y.shape)}\")   # (B, 1, 128, 128, 128)\n",
    "        print(f\"Input stats:  min={x.min():.3g}, max={x.max():.3g}, mean={x.mean():.3g}\")\n",
    "        print(f\"Target stats: min={y.min():.3g}, max={y.max():.3g}, mean={y.mean():.3g}\")\n",
    "        break  # í•œ ë°°ì¹˜ë§Œ í™•ì¸\n",
    "\n",
    "inspect_batch(train_loader, \"train\")\n",
    "inspect_batch(val_loader, \"val\")\n",
    "inspect_batch(test_loader, \"test\")\n",
    "\n",
    "print(\"\\nâœ… All loaders initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch version: 2.4.1+cu121\n",
      "ğŸš€ GPU available: True\n",
      "ğŸ§  GPU name: Tesla V100-SXM2-32GB\n",
      "ğŸ’¾ Total memory: 31.74 GiB\n",
      "ğŸ“¦ Reserved memory: 0.00 GiB\n",
      "ğŸ“ˆ Allocated memory: 0.00 GiB\n",
      "ğŸŸ¢ Free memory in reserved: 0.00 GiB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: í™˜ê²½ í™•ì¸\n",
    "import torch\n",
    "\n",
    "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
    "print(f\"ğŸš€ GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"ğŸ§  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory / 1024**3  # GiB\n",
    "    reserved_memory = torch.cuda.memory_reserved(device) / 1024**3  # GiB\n",
    "    allocated_memory = torch.cuda.memory_allocated(device) / 1024**3  # GiB\n",
    "    free_memory = reserved_memory - allocated_memory  # GiB\n",
    "\n",
    "    print(f\"ğŸ’¾ Total memory: {total_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“¦ Reserved memory: {reserved_memory:.2f} GiB\")\n",
    "    print(f\"ğŸ“ˆ Allocated memory: {allocated_memory:.2f} GiB\")\n",
    "    print(f\"ğŸŸ¢ Free memory in reserved: {free_memory:.2f} GiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 20:34:57,658 | INFO | data_loader | ğŸ“‚ Split 'train': 8202 files (8202/10253 train-val split, 1267 test files)\n",
      "2025-10-14 20:35:03,298 | INFO | data_loader | âœ… Valid files kept: 8202 / 8202\n",
      "2025-10-14 20:35:03,301 | INFO | data_loader | ğŸ” Initializing ASIMHDF5Dataset | samples: 8202 | target: rho\n",
      "2025-10-14 20:35:03,302 | INFO | data_loader | ğŸ“¦ Split='train' | batches of 2 | files=8202 | target='rho' | dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample loaded: input shape = (2, 2, 128, 128, 128), output shape = (2, 1, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: ë°ì´í„°ì…‹ ë¡œë”© (A-SIM ê·œê²©)\n",
    "import os, sys\n",
    "import torch\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸(srcê°€ ìˆëŠ” ìƒìœ„ í´ë”) ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# A-SIMìš© ë°ì´í„°ë¡œë” ì„í¬íŠ¸\n",
    "from src.data_loader import get_dataloader\n",
    "\n",
    "# asim_paths.yaml ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆë‹¤ê³  ê°€ì •)\n",
    "yaml_path = os.path.join(project_root, \"etc/asim_paths.yaml\")\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "# - split='train'ì€ training/*.hdf5 ì¤‘ ì•ë¶€ë¶„(ê¸°ë³¸ 80%)ì„ ì‚¬ìš©\n",
    "# - target_field='rho' ì´ë©´ output_rhoë¥¼ íƒ€ê¹ƒìœ¼ë¡œ ì‚¬ìš©\n",
    "loader = get_dataloader(\n",
    "    yaml_path=yaml_path,\n",
    "    split=\"train\",             # 'val' / 'test'ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    target_field=\"rho\",        # 'tscphi' ì‚¬ìš© ì‹œ í¬í…ì…œ ìŠ¤ì¼€ì¼/í‰ê·  ì œê±° ìë™ ì ìš©\n",
    "    train_val_split=0.8,       # train/val ë¹„ìœ¨ ì¡°ì • ê°€ëŠ¥\n",
    ")\n",
    "\n",
    "# í•œ ë°°ì¹˜ í™•ì¸\n",
    "x, y = next(iter(loader))\n",
    "print(f\"âœ… Sample loaded: input shape = {tuple(x.shape)}, output shape = {tuple(y.shape)}\")\n",
    "# ê¸°ëŒ€ í˜•ìƒ: input=(B, 2, 128, 128, 128), output=(B, 1, 128, 128, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2067304/662931745.py:56: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ViT model (full) loaded and set to training mode.\n",
      "ğŸ“ Dummy input: torch.Size([2, 2, 128, 128, 128]) â†’ Prediction shape: torch.Size([2, 1, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: ViT ì´ˆê¸°í™” for scalar regression from full 3D volume (A-SIM, 128Â³ cube)\n",
    "from src.model import VoxelViTUNet3D as ViT3D\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# ì…ë ¥/íŒ¨ì¹˜ ì„¤ì •\n",
    "# -------------------------\n",
    "input_shape = (128, 128, 128)   # (D, H, W)\n",
    "patch_spatial = 16               # H/W ë°©í–¥ íŒ¨ì¹˜ í¬ê¸°\n",
    "patch_depth = 16                 # D ë°©í–¥ íŒ¨ì¹˜ í¬ê¸°\n",
    "\n",
    "# (ì´ì „ì— frames, image_size ë“±ì€ ì •ì˜ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¸íŒ…)\n",
    "D, H, W = input_shape\n",
    "pf, ph, pw = patch_depth, patch_spatial, patch_spatial\n",
    "\n",
    "# -------------------------\n",
    "# ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "# -------------------------\n",
    "emb_dim = 256\n",
    "depth = 3\n",
    "heads = 8\n",
    "mlp_dim = 512\n",
    "\n",
    "# -------------------------\n",
    "# ë””ë°”ì´ìŠ¤/ì‹œë“œ\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# -------------------------\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# -------------------------\n",
    "model_name = \"full\"\n",
    "model = ViT3D(\n",
    "    image_size=(D, H, W),                     # (D,H,W)\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    patch_size=(pf, ph, pw),                  # Conv3d kernel\n",
    "    patch_stride=(pf, ph, pw),                # â† non-overlap; ê²¹ì¹˜ë ¤ë©´ (pf//2, ph//2, pw//2)\n",
    "    dim=emb_dim,\n",
    "    depth=depth,\n",
    "    heads=heads,\n",
    "    mlp_dim=mlp_dim,\n",
    "    encoder_channels=(32, 64, 128),\n",
    "    decoder_channels=(256, 128, 64),\n",
    ").to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "# -------------------------\n",
    "# ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ forward í…ŒìŠ¤íŠ¸\n",
    "# -------------------------\n",
    "x_dummy = torch.randn(2, 2, D, H, W, device=device)  # [B, C, D, H, W]\n",
    "with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "    y_dummy = model(x_dummy)\n",
    "\n",
    "print(f\"âœ… ViT model ({model_name}) loaded and set to training mode.\")\n",
    "print(f\"ğŸ“ Dummy input: {x_dummy.shape} â†’ Prediction shape: {y_dummy.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "===========================================================================================================================================================\n",
       "VoxelViTUNet3D                                          [2, 2, 128, 128, 128]     [2, 1, 128, 128, 128]     2,048                     --\n",
       "â”œâ”€CNNEncoder: 1-1                                       [2, 2, 128, 128, 128]     [2, 128, 32, 32, 32]      --                        --\n",
       "â”‚    â””â”€DoubleConv: 2-1                                  [2, 2, 128, 128, 128]     [2, 32, 128, 128, 128]    --                        --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-1                             [2, 2, 128, 128, 128]     [2, 32, 128, 128, 128]    29,504                    --\n",
       "â”‚    â””â”€Down: 2-2                                        [2, 32, 128, 128, 128]    [2, 64, 64, 64, 64]       --                        --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-2                             [2, 32, 128, 128, 128]    [2, 64, 64, 64, 64]       166,144                   --\n",
       "â”‚    â””â”€Down: 2-3                                        [2, 64, 64, 64, 64]       [2, 128, 32, 32, 32]      --                        --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-3                             [2, 64, 64, 64, 64]       [2, 128, 32, 32, 32]      664,064                   --\n",
       "â”œâ”€ConvPatchEmbedding3D: 1-2                             [2, 128, 32, 32, 32]      [2, 8, 256]               --                        --\n",
       "â”‚    â””â”€Conv3d: 2-4                                      [2, 128, 32, 32, 32]      [2, 256, 2, 2, 2]         134,217,728               [16, 16, 16]\n",
       "â”œâ”€Dropout: 1-3                                          [2, 8, 256]               [2, 8, 256]               --                        --\n",
       "â”œâ”€TransformerEncoder: 1-4                               [2, 8, 256]               [2, 8, 256]               --                        --\n",
       "â”‚    â””â”€ModuleList: 2-5                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-4                             --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-5                             --                        --                        788,480                   --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-6                             --                        --                        788,480                   --\n",
       "â”‚    â””â”€LayerNorm: 2-6                                   [2, 8, 256]               [2, 8, 256]               512                       --\n",
       "â”œâ”€UNetDecoder3D: 1-5                                    [2, 256, 2, 2, 2]         [2, 1, 128, 128, 128]     --                        --\n",
       "â”‚    â””â”€Conv3dReLU: 2-7                                  [2, 256, 2, 2, 2]         [2, 256, 2, 2, 2]         --                        --\n",
       "â”‚    â”‚    â””â”€Conv3d: 3-7                                 [2, 256, 2, 2, 2]         [2, 256, 2, 2, 2]         1,769,472                 [3, 3, 3]\n",
       "â”‚    â”‚    â””â”€BatchNorm3d: 3-8                            [2, 256, 2, 2, 2]         [2, 256, 2, 2, 2]         512                       --\n",
       "â”‚    â”‚    â””â”€ReLU: 3-9                                   [2, 256, 2, 2, 2]         [2, 256, 2, 2, 2]         --                        --\n",
       "â”‚    â””â”€ModuleList: 2-8                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€DecoderBlock: 3-10                          [2, 256, 2, 2, 2]         [2, 128, 64, 64, 64]      1,368,704                 --\n",
       "â”‚    â”‚    â””â”€DecoderBlock: 3-11                          [2, 128, 64, 64, 64]      [2, 64, 128, 128, 128]    342,336                   --\n",
       "â”‚    â””â”€Conv3d: 2-9                                      [2, 64, 128, 128, 128]    [2, 1, 128, 128, 128]     1,729                     [3, 3, 3]\n",
       "===========================================================================================================================================================\n",
       "Total params: 140,928,193\n",
       "Trainable params: 140,928,193\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 2.28\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 33.55\n",
       "Forward/backward pass size (MB): 18557.04\n",
       "Params size (MB): 563.70\n",
       "Estimated Total Size (MB): 19154.30\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Batch=2, Channels=2, D=H=W=128\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(2, 2, 128, 128, 128),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"],\n",
    "    depth=3,            # keep output readable\n",
    "    device=str(device), # run summary on the same device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
